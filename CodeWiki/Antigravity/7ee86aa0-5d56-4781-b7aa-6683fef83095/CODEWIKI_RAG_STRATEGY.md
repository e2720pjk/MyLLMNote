# CodeWiki RAG & Data Strategy: The "Structure-First" Paradigm

This document organizes your insights on "Semantics vs. Structure" and defines the optimal RAG architecture.

## 1. Core Philosophy: "Semantics is Lossy Compression"
Your insight is profound and correct.
*   **Semantics (LLM generated)** is a "Human-Readable Compression" of code. It is lossy, approximate, and distinct from the code itself.
*   **Structure (AST/Graph)** is the "Ground Truth". It is exact, executable, and rigorous.

**Strategic Pivot:**
We stop treating "Text Documents" as the database. Instead, "Documents" are just a **View Layer** generated on demand from the **Structured Data Lake**.

---

## 2. The Separation of Concerns (Storage vs. View)

You asked: *"Should output be separated from storage?"* **YES.**

### Layer 1: The Raw Data (The "Truth")
*   **Code:** The actual files.
*   **Graph:** CPG (Joern) + Dependency Graph (CGR).
*   **Git:** History and Diffs.
*   *(No LLM involved here. 100% deterministic.)*

### Layer 2: The Semantic Index (The "Map")
*   **Vector Store (AutoMem):** "This module handles User Auth."
*   **Summaries:** High-level descriptions generated by Recursive Agents.
*   *(LLM used here to create "Search Tags" and "Explanations", not facts.)*

### Layer 3: The View (The "Document")
*   **Static Doc:** A Markdown file rendered by combining Layer 1 (Signatures) + Layer 2 (Summaries).
*   **Dynamic Chat:** An answer generated by retrieving Layer 2 (Concept) + Layer 1 (Details).

**Value:**
If you change the "View Template" (e.g., "Show me PlantUML diagrams instead of Text"), you *don't* re-analyze the code. You just re-render the view from Layer 1 & 2.

---

## 3. The Hybrid RAG Strategy
*Question: Should RAG be Semantic, Specific Index, or Mixed?*
**Answer: Structured Routing (Hybrid).**

A "Smart Agent" sits in front and routes the query:

| Query Type | Route | Data Source | Example |
| :--- | :--- | :--- | :--- |
| **"Find Fact"** | **SQL / Cypher** | Layer 1 (Graph) | "Find all functions calling `delete_user`." |
| **"Explain Concept"** | **Vector Search** | Layer 2 (AutoMem) | "How does the payment flow work?" |
| **"Debug Issue"** | **Traceability** | Layer 1 (Git) + Layer 2 | "Why was `retry_logic` added?" |

**The "Integrated Index" Approach:**
Do not stuff everything into Vector DB.
*   **Vector DB:** Stores `Concept -> NodeID`.
*   **Graph DB:** Stores `NodeID -> Structure`.
*   **Process:**
    1.  User asks "Auth".
    2.  Vector DB returns `NodeID: src/auth/service.py`.
    3.  RAG Agent retrieves *Structure* of `service.py` from Graph (not from Vector text).
    4.  LLM generates answer.

---

## 4. Assessment of Your Ideas

1.  **"Semantics as Compression"**:
    *   **Value:** **High**. Prevents hallucination. We rely on Structure for facts, Semantics only for search/understanding.
2.  **"Independent Storage Layer"**:
    *   **Value:** **Critical**. Enables "Multiple Views" (Docs, Mocking, Chat) from one analysis.
3.  **"Mixing Semantic -> Index -> Static Data"**:
    *   **Value:** **High**. This is the definition of "GraphRAG". The "Index" links the fuzzy User Query to the precise Static Data.

## 5. Summary Recommendation
Build a **"Headless CodeWiki"**.
1.  **Backend:** Runs Analysis -> Saves compact JSON/Graph Data (The "Database").
2.  **Frontend A (Markdown):** Reads Database -> Templating Engine -> `.md` files.
3.  **Frontend B (Chat):** Reads Database -> RAG Engine -> Answers.

This decouple is the "Solid Principles" applied to Data Architecture.
