# CodeWiki Strategic Vision: From "Documentation" to "Code Intelligence"

## 1. Executive Summary
This report summarizes our analysis of CodeWiki's evolution.
The core conclusion is a **Strategic Pivot**: We are moving from a *Markdown Generator* to a **Decoupled Code Intelligence Platform**.

**The Big Shift:**
*   **Old View:** "Read code -> Ask LLM -> Write Markdown." (Linear, Fragile)
*   **New View:** "Ingest Code/Git -> Build Knowledge Graph -> Service Multiple Apps (Docs, Mocks, QA)." (Centralized, Robust)

---

## 2. The Decoupled Architecture (The "Data Lake" Model)

You asked: *"Can we separate storage, analysis, and generation?"*
**Answer: Yes. This is the definition of the new architecture.**

### Layer 1: The "Truth" (Storage & Data)
This layer contains raw facts. It is **immutable** and **queryable**.
*   **Source Code (AST):** The "What" (Syntax).
*   **Joern (CPG):** The "How" (Flow & Behavior).
*   **Git Evidence (Index):** The "When & Why" (History & Intent).
    *   *Note:* Stores `CommitID` + `Semantic Summary`. Does NOT store raw diffs.

### Layer 2: The "Brain" (Analysis Service)
This layer answers questions. It does not generate text; it yields **Structured Data**.
*   **Orchestrator:** "Map the dependency tree."
*   **Semantic Analyzer:** "Why did `Login` change recently?" (Returns: `Fix CVE-2024` + Link to Commit).
*   **Constraint Solver:** "What inputs cause `crash()`?" (Returns: `input < 0`).

### Layer 3: The "View" (Applications)
This layer consumes Layer 2 to produce user value.
*   **App A (CodeWiki):** Renders "Static Docs" (Markdown).
*   **App B (ChatBot):** Renders "Dynamic Answers" (Text).
*   **App C (MockGen):** Renders "Test Scenarios" (Code).

---

## 3. Advanced Applications (Beyond Documentation)

You asked: *"What other applications can this architecture support to avoid LLM hallucinations?"*

### Application 1: High-Fidelity Mock Generation (The "Anti-Hallucination" Killer Feature)
*   **Problem:** LLMs guess what a function needs. They often guess wrong (e.g., missing a required field in a JSON object).
*   **The Graph Solution:**
    1.  **Joern Query:** "Find all field accesses on parameter [config](file:///Users/caishanghong/Shopify/cli-tool/.editorconfig) inside [process(config)](file:///Users/caishanghong/Shopify/cli-tool/CodeWiki-2/codewiki/src/be/agent_orchestrator.py#68-167)."
    2.  **Result:** `config.url`, `config.timeout`, `config.retry_count`.
    3.  **Action:** Feed this **exact list** to the LLM.
    4.  **Outcome:** The LLM generates a Mock that is **guaranteed** to satisfy the code's runtime requirements. No guessing.

### Application 2: Automated Security Auditing (Taint Analysis)
*   **Problem:** "Is my SQL query safe?"
*   **The Graph Solution:**
    1.  **Joern Query:** "Trace data flow from `HTTP Request` to `SQL Execute`."
    2.  **Check:** "Does it pass through a `Sanitizer` function?"
    3.  **Outcome:** If No, flag it. This is **deterministically provable** without an LLM.

### Application 3: "Impact-Aware" Refactoring
*   **Problem:** "If I change `User.id` from [int](file:///Users/caishanghong/Shopify/cli-tool/.yamllint) to `uuid`, what breaks?"
*   **The Graph Solution:**
    1.  **CGR Query:** Find all functions that call `User.getId()`.
    2.  **Joern Query:** Filter those that perform arithmetic (e.g., `id + 1`).
    3.  **Outcome:** A precise "Hit List" of code that will break. The LLM can then draft the refactoring plan for *those specific spots*.

---

## 4. Addressing "Git Traceability" (The Evidence Chain)

You asked: *"How do we ensure trust in the history summaries?"*

**The "Trust but Verify" UI Pattern:**
*   **The Summary:** "Fixed critical auth bug." (Generated by LLM = **Low Trust**)
*   **The Evidence:** `[Commit a1b2c]` (Hard Link to Git = **High Trust**)

**Workflow:**
1.  **Reader** sees the Summary. It gives context.
2.  **Reader** doubts the Summary.
3.  **Reader** clicks the Evidence.
4.  **System** fetches the *real* Diff.
5.  **Trust is restored.**

We do not ask the user to trust the LLM. We ask them to use the LLM as a *search engine* for the Evidence.

---

## 5. Conclusion & Recommendation

The greatest value of this project is **not** generating Markdown files.
The greatest value is **structuring the chaos of a codebase into a Knowledge Graph.**

Once you have this Graph (AST + Flow + History):
1.  **CodeWiki** becomes just one "Printer" for this data.
2.  **Mock Generation** becomes a "Simulator" for this data.
3.  **QA Bots** become "Auditors" for this data.

**Recommendation:**
Proceed with the **"Decoupled Implementation Strategy"** ([CODEWIKI_IMPLEMENTATION_STRATEGY.md](file:///Users/caishanghong/.gemini/antigravity/brain/7ee86aa0-5d56-4781-b7aa-6683fef83095/CODEWIKI_IMPLEMENTATION_STRATEGY.md)). It builds the foundation for this Platform vision while keeping the current CodeWiki tool functional and backward-compatible.
